\section{Independent Models}

\begin{frame}{Statistical Models}
    \begin{block}{planetmath.org}
    A \emph{statistical model} is usually parameterised by a function, called a \emph{parametrisation}
    $$ \Theta \ra \mc{P}, \quad \text{given by} \quad \theta \mapsto P_{\theta},\quad \text{so that}\quad \mc{P} = \{ P_{\theta} : \theta \in \Theta \}, $$
    where $\Theta$ is the \emph{parameter space}. $\Theta$ is usually a subset of $\RR^{n}$.
    \end{block}

    \begin{block}{McCullagh, 2002}
    This should be defined using category theory.
    \end{block}
\end{frame}

\begin{frame}{Two-by-Two Contingency Tables}
    
    A contingency table contains counts obtained by cross-classifying observed cases according to two or more discrete criteria.

    \begin{block}{Example}
        TODO: Figure (Florida death sentences)
    \end{block}

    We ask whether the sentences were made independently of the defendant's race.
\end{frame}

\begin{frame}{Two-by-Two Contingency Tables}
    
    \begin{itemize}
        \item Classify using two criteria with $r$ and $c$ levels, yields two random variables $X$ and $Y$. 
        \item Code outcomes as $[r] := \{1,\ldots, r\}$, and $[c] := \{ 1, \ldots, c \}$.
    \end{itemize}
    
    All information about $X$ and $Y$ is contained in the \emph{joint probabilities}
    $$ p_{ij} = P(X = i; Y = j), \quad i \in [r],\ j \in [c]. $$

    \begin{itemize}
        \item These in turn determine the \emph{marginal probabilities}:
    \end{itemize}

    \begin{equation*}
        \begin{split}
            p_{i+} &:= \sum_{j = 1}^{c} p_{ij} = P(X = i), \quad i \in [r], \\
            p_{+j} &:= \sum_{i = 1}^{r} p_{ij} = P(Y = j), \quad j \in [c].
        \end{split}
    \end{equation*}

\end{frame}

\begin{frame}{Independence}
    The distribution $P$ is called \emph{independent} is each probability is the product of the corresponding \emph{marginal probabilities}:
    $$ P_{ijk} = P_{i++} \cdot P_{+j+} \cdot P_{++k}. $$
    A marginal probability is the probability of an event irrespective of the outcomes of the other variables, that is:
    $$ P_{i++} = \Prob(X = i) = \sum_{j=1}^{b} \sum_{k=1}^{c} P_{ijk}. $$
\end{frame}

\begin{frame}{Independence Model}
    The \emph{independence model} has the parametric representation:
    \begin{equation*}
        \begin{split}
            \Theta = \Delta_{a-1} \times \Delta_{b-c} \times \Delta_{c-1} &\ra \Delta = \Delta_{abc - 1}, \\
            (\alpha,\beta,\gamma) \mapsto (P_{ijk}) = (\alpha_{i}\beta_{j}\gamma_{k}).
        \end{split}
    \end{equation*}

    The image is known as the \emph{Segre variety} in algebraic geometry.
\end{frame}

\begin{frame}{Foray Into Algebraic Geometry}
    \begin{block}{Projective Space}
    Playing field is $n$\emph{-dimensional projective space}, $\PP^{n}$:
        $$ \PP^{n} := \{ (z_{0}, \ldots, z_{n}) \in \CC^{n} \} / (\vb{x} \sim \lambda \cdot \vb{y}), \quad \lambda \neq 0, $$
    that is, its elements consists of \emph{lines through the origin} in $\CC^{n}$.
    \end{block}
    
    TODO: FIGURE
\end{frame}

\begin{frame}{Varieties}
        \emph{Varieties} are the geometric objects studied in algebraic\footnote{classical algebraic geometry} geometry, which are the \emph{vanishing sets} (Verschwindungsmenge) for polynomials.

        Example:
        $$ S^{1} = \{ (x,y) \in \RR^{2} : x^{2} + y^{2} = 1 \} = V( x^{2} + y^{2} - 1 ). $$

    TODO: FIGURE
\end{frame}

\begin{frame}{Segre Varieties}
        \emph{Segre varieties} come from $\sigma: \PP^{n} \times \PP^{m} \ra \PP^{(n+1)(m+1) - 1}$, that sends $([X],[Y])$ to the pairwise products of their components:
            $$ \sigma : ([X_{0}, \ldots, X_{n}], [Y_{0}, \ldots, Y_{m}]) \mapsto [\ldots, X_{i}Y_{j}, \ldots ], $$

        \begin{block}{Example}
        $$\sigma : \PP^{1} \times \PP^{1} \ra \PP^{3},\ ([X_{0}, X_{1}], [Y_{0}, Y_{1}]) \mapsto [ X_{0}Y_{0}, X_{0}Y_{1}, X_{1}Y_{0}, X_{1}Y_{1} ].  $$
        
        Set $[ X_{0}Y_{0}, X_{0}Y_{1}, X_{1}Y_{0}, X_{1}Y_{1} ] = [Z_{0}, Z_{1}, Z_{2}, Z_{3}]$, and observe $Z_{0}Z_{3} - Z_{1}Z_{2} = 0$,
        $$ \rightsquigarrow \det \begin{pmatrix} Z_{0} & Z_{1} \\ Z_{2} & Z_{3} \end{pmatrix} = 0 \iff \rank \begin{pmatrix} Z_{0} & Z_{1} \\ Z_{2} & Z_{3} \end{pmatrix} \leq 1. $$
        \end{block}
\end{frame}

\begin{frame}{Determinental Varieties}
        
    $\sigma(\PP^{1} \times \PP^{1}) = \{ [Z_{0}, Z_{1}, Z_{2}, Z_{3}] : \rank \begin{pmatrix} Z_{0} & Z_{1} \\ Z_{2} & Z_{3} \end{pmatrix} \leq 1 \} $ is an example of a \emph{determinantal variety}.

     

\end{frame}